#!/usr/bin/env python3
import pandas as pd
import requests
import os

os.makedirs("data_final/contracts", exist_ok=True)
OUT = "data_final/contracts/exploit_metadata_extended.csv"

SOURCES = [
    "https://api.defillama.com/hacks",       # DeFiLlama exploit registry
    "https://api.rekt.news/api/incidents",   # REKT DB
    "https://hacked.slowmist.io/en.json"     # SlowMist archives
]

rows = []

for url in SOURCES:
    try:
        print(f"üåê Fetching exploits from {url}")
        data = requests.get(url, timeout=20).json()
        for entry in data.get("incidents", data):
            rows.append({
                "protocol": entry.get("protocol", ""),
                "date": entry.get("date", ""),
                "loss_usd": entry.get("loss", entry.get("amount", "")),
                "attack_vector": entry.get("type", entry.get("title", "")),
                "source": url
            })
    except Exception as e:
        print(f"‚ö†Ô∏è Failed {url}: {e}")

df = pd.DataFrame(rows).drop_duplicates(subset=["protocol", "date"])
df.to_csv(OUT, index=False)
print(f"‚úÖ Saved extended exploit metadata ‚Üí {OUT} ({len(df)} rows)")