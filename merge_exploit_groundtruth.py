#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# /Users/ruiyeshi/defi_protocol_security/merge_exploit_groundtruth.py

import pandas as pd
from pathlib import Path

# --- Ensure paths exist ---
Path("data_raw/contracts").mkdir(parents=True, exist_ok=True)
Path("data_raw/incidents").mkdir(parents=True, exist_ok=True)
Path("outputs").mkdir(parents=True, exist_ok=True)
Path("logs").mkdir(parents=True, exist_ok=True)

# --- File paths ---
CONTRACTS = Path("data_raw/contracts/verified_contracts_expanded.csv")
INC = Path("data_raw/incidents/exploit_catalog.csv")
OUT = Path("outputs/exploit_labels_merged.csv")

# --- Check existence ---
if not CONTRACTS.exists():
    raise SystemExit(f"Missing verified contracts file: {CONTRACTS}")
if not INC.exists():
    raise SystemExit(f"Missing exploit catalog file: {INC}")

# --- Load datasets ---
c = pd.read_csv(CONTRACTS)
i = pd.read_csv(INC, parse_dates=["exploit_date"])

# --- Normalize names ---
c["protocol_l"] = c["protocol"].astype(str).str.lower().fillna("")
i["protocol_l"] = i["protocol"].astype(str).str.lower().fillna("")

# --- Merge safely ---
merge_cols = [col for col in ["protocol_l", "exploit_date", "loss_usd", "exploit_type"] if col in i.columns]
lab = c.merge(i[merge_cols], on="protocol_l", how="left")

# --- Derived columns ---
lab["exploited_flag"] = lab["exploit_date"].notna().astype(int)
lab["first_tvl_ts"] = pd.NaT
lab["obs_end_ts"] = pd.Timestamp.utcnow().normalize()

# --- Keep core architecture columns ---
keep = [
    "chain", "contract_address", "protocol", "category", "deploy_ts",
    "first_tvl_ts", "obs_end_ts", "exploited_flag",
    "exploit_date", "loss_usd", "exploit_type"
]
lab[keep].to_csv(OUT, index=False)

print(f"✅ Saved merged dataset → {OUT} ({len(lab)} rows)")