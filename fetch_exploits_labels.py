#!/usr/bin/env python3
"""
fetch_exploits_labels.py
Labels each (protocol, chain, contract_address) from data_raw/contracts/contract_registry.csv
with exploit info pulled from DeFiLlama's public hacks dataset.

Output: data_raw/contracts/exploit_metadata_final.csv
"""

import re
import json
from pathlib import Path
from datetime import datetime

import pandas as pd
import requests
from tqdm import tqdm


# ---------- paths ----------
ROOT = Path(__file__).resolve().parent
DATA_DIR = ROOT / "data_raw" / "contracts"
DATA_DIR.mkdir(parents=True, exist_ok=True)

REGISTRY_CSV = DATA_DIR / "contract_registry.csv"
OUT_CSV      = DATA_DIR / "exploit_metadata_final.csv"


# ---------- helpers ----------
def norm_name(s: str) -> str:
    """normalize protocol names for matching"""
    if not isinstance(s, str):
        return ""
    s = s.lower()
    # strip trailing versions and punctuation
    s = re.sub(r"\b(v\d+|v\d+\.\d+)\b", "", s)   # remove v2 / v3 / v2.5 etc
    s = s.replace(" amm", "").replace(" dex", "")
    s = s.replace(" protocol", "").replace(" finance", "")
    s = s.replace(" perp", " perpetual")
    s = re.sub(r"[^a-z0-9]+", "", s)
    return s

def norm_addr(a: str) -> str:
    if not isinstance(a, str):
        return ""
    return a.lower()


def parse_llama_hacks() -> pd.DataFrame:
    """Fetch & normalize DeFiLlama hacks dataset."""
    url = "https://api.llama.fi/hacks"
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    data = r.json()

    rows = []
    for item in data:
        # The schema can vary slightly over time; be defensive
        proto   = item.get("protocol", item.get("project", item.get("name", "")))
        chains  = item.get("chains") or item.get("chain") or []
        if isinstance(chains, str):
            chains = [chains]
        date    = item.get("date", item.get("timestamp"))
        # convert to ISO date
        if isinstance(date, (int, float)):
            dt = datetime.utcfromtimestamp(int(date)).date().isoformat()
        else:
            try:
                dt = str(pd.to_datetime(date, utc=True).date())
            except Exception:
                dt = None

        amount  = item.get("amountUSD") or item.get("loss") or item.get("value") or 0
        try:
            amount = float(amount)
        except Exception:
            amount = None

        category = item.get("category") or item.get("type") or item.get("vector")
        url_src  = item.get("url") or item.get("link") or ""

        # exploited contract addresses (if present)
        addrs = []
        for k in ("exploitedContracts", "addresses", "contracts"):
            v = item.get(k)
            if not v:
                continue
            if isinstance(v, str):
                # sometimes it's a stringified list
                try:
                    v = json.loads(v)
                except Exception:
                    v = [v]
            if isinstance(v, list):
                addrs.extend(v)

        addrs = [norm_addr(a) for a in addrs if isinstance(a, str)]

        rows.append({
            "hack_protocol": proto or "",
            "hack_protocol_norm": norm_name(proto or ""),
            "hack_chains": chains,
            "hack_date": dt,
            "loss_usd": amount,
            "exploit_type": category,
            "source_link": url_src,
            "exploited_addresses": addrs
        })

    return pd.DataFrame(rows)


# ---------- main ----------
def main():
    if not REGISTRY_CSV.exists():
        raise FileNotFoundError(
            f"Missing {REGISTRY_CSV}. Run your contract registry step first "
            "(fetch_contract_registry.py)."
        )

    reg = pd.read_csv(REGISTRY_CSV)
    # keep only rows that actually have an address (we can still do name-only matching if absent)
    reg["protocol_name"] = reg.get("protocol_name", "").astype(str)
    reg["chain"] = reg.get("chain", "").astype(str)
    reg["contract_address"] = reg.get("contract_address", "").astype(str)

    reg["protocol_norm"] = reg["protocol_name"].map(norm_name)
    reg["addr_norm"] = reg["contract_address"].map(norm_addr)

    print(f"ðŸ“¦ Loaded contract registry â†’ {len(reg)} rows")

    hacks = parse_llama_hacks()
    print(f"ðŸ”¥ Loaded DeFiLlama hacks dataset â†’ {len(hacks)} events")

    # Expand hacks per chain for easier matching
    hacks_expanded = (
        hacks.explode("hack_chains").rename(columns={"hack_chains": "hack_chain"})
    )
    hacks_expanded["hack_chain"] = hacks_expanded["hack_chain"].fillna("")

    # 1) address-level match (most precise)
    addr_map = {}
    for _, h in hacks_expanded.iterrows():
        for a in h.get("exploited_addresses", []) or []:
            addr_map.setdefault(a, []).append(h)

    records = []
    for _, row in tqdm(reg.iterrows(), total=len(reg), desc="Labeling exploits"):
        pnorm = row["protocol_norm"]
        chain = row["chain"]
        addr  = row["addr_norm"]

        matched = []

        # A) address hit
        if addr and addr in addr_map:
            cands = addr_map[addr]
            # filter by chain if hack has one
            cands = [h for h in cands if not h["hack_chain"] or h["hack_chain"].lower() == chain.lower()]
            matched.extend(cands)

        # B) protocol-name hit (fallback)
        if not matched and pnorm:
            by_name = hacks_expanded[hacks_expanded["hack_protocol_norm"] == pnorm]
            if chain:
                by_name = by_name[(by_name["hack_chain"].str.lower() == chain.lower()) | (by_name["hack_chain"] == "")]
            matched.extend(by_name.to_dict("records"))

        if matched:
            # choose the most recent (max date) if multiple
            mdf = pd.DataFrame(matched)
            try:
                mdf["_dt"] = pd.to_datetime(mdf["hack_date"], errors="coerce")
            except Exception:
                mdf["_dt"] = pd.NaT
            mdf = mdf.sort_values("_dt").tail(1).drop(columns=["_dt"], errors="ignore")
            m = mdf.iloc[0].to_dict()
            records.append({
                "protocol_name": row["protocol_name"],
                "chain": row["chain"],
                "contract_address": row["contract_address"],
                "exploit": True,
                "exploit_date": m.get("hack_date"),
                "loss_usd": m.get("loss_usd"),
                "exploit_type": m.get("exploit_type"),
                "source_link": m.get("source_link")
            })
        else:
            records.append({
                "protocol_name": row["protocol_name"],
                "chain": row["chain"],
                "contract_address": row["contract_address"],
                "exploit": False,
                "exploit_date": None,
                "loss_usd": None,
                "exploit_type": None,
                "source_link": None
            })

    out = pd.DataFrame(records)
    out.to_csv(OUT_CSV, index=False)
    positives = int(out["exploit"].sum())
    print(f"âœ… Saved exploit labels â†’ {OUT_CSV} "
          f"({len(out)} rows, {positives} exploited, {len(out)-positives} clean)")


if __name__ == "__main__":
    main()