

import os
import json
import pandas as pd
from tqdm import tqdm
from fuzzywuzzy import fuzz, process
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

# Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_PROCESSED = os.path.join(BASE_DIR, "../data_processed")
DATA_RAW = os.path.join(BASE_DIR, "../data_raw/contracts")

EXPLOITS_PATH = os.path.join(DATA_PROCESSED, "exploits_normalized.json")
ENRICHED_JSON_PATH = os.path.join(DATA_PROCESSED, "exploits_normalized_enriched.json")
ENRICHED_CSV_PATH = os.path.join(DATA_PROCESSED, "exploits_normalized_enriched.csv")

# Audit metadata files
AUDIT_CERTIK_PATH = os.path.join(DATA_RAW, "audit_metadata_certik.csv")
AUDIT_DEFISAFETY_PATH = os.path.join(DATA_RAW, "audit_metadata_defisafety.csv")
AUDIT_GITHUB_PATH = os.path.join(DATA_RAW, "audit_metadata_github.csv")

# Contract-level data
VERIFIED_CONTRACTS_PATH = os.path.join(DATA_RAW, "verified_contracts_expanded.csv")

# Helper: load JSON
def load_json(path):
    with open(path, "r") as f:
        return json.load(f)

# Helper: save JSON
def save_json(obj, path):
    with open(path, "w") as f:
        json.dump(obj, f, indent=2)

def main():
    print("Loading exploits dataset...")
    exploits = load_json(EXPLOITS_PATH)
    print(f"Loaded {len(exploits)} exploit incidents.")

    print("Loading audit metadata datasets...")
    certik = pd.read_csv(AUDIT_CERTIK_PATH)
    defisafety = pd.read_csv(AUDIT_DEFISAFETY_PATH)
    github = pd.read_csv(AUDIT_GITHUB_PATH)

    print("Loading contract-level metadata...")
    contracts = pd.read_csv(VERIFIED_CONTRACTS_PATH)

    # Normalize names for matching
    def norm_name(s):
        if not isinstance(s, str):
            return ""
        return s.lower().strip()

    certik['norm_name'] = certik['protocol'].map(norm_name) if 'protocol' in certik.columns else ""
    defisafety['norm_name'] = defisafety['protocol'].map(norm_name) if 'protocol' in defisafety.columns else ""
    github['norm_name'] = github['protocol'].map(norm_name) if 'protocol' in github.columns else ""
    contracts['norm_name'] = contracts['protocol'].map(norm_name) if 'protocol' in contracts.columns else ""
    contracts['address_norm'] = contracts['address'].str.lower() if 'address' in contracts.columns else ""

    # Prebuild fuzzy sets for protocol/project names
    certik_names = certik['norm_name'].dropna().unique().tolist()
    defisafety_names = defisafety['norm_name'].dropna().unique().tolist()
    github_names = github['norm_name'].dropna().unique().tolist()
    contracts_names = contracts['norm_name'].dropna().unique().tolist()
    contracts_addresses = contracts['address_norm'].dropna().unique().tolist()

    # For progress
    enriched = []
    unmatched = []

    for incident in tqdm(exploits, desc="Enriching incidents"):
        # Extract possible keys for matching
        protocol = norm_name(incident.get("protocol") or incident.get("project") or incident.get("name"))
        addresses = incident.get("addresses", []) or []
        addresses_norm = [a.lower() for a in addresses if isinstance(a, str)]

        # --- Audit info enrichment ---
        # Certik
        certik_row = certik[certik['norm_name'] == protocol]
        if certik_row.empty and protocol:
            # Fuzzy match
            match, score = process.extractOne(protocol, certik_names, scorer=fuzz.token_sort_ratio)
            if score >= 85:
                certik_row = certik[certik['norm_name'] == match]
        audited_by_certik = not certik_row.empty
        audit_score_certik = certik_row['score'].iloc[0] if audited_by_certik and 'score' in certik_row.columns else None

        # Defisafety
        defisafety_row = defisafety[defisafety['norm_name'] == protocol]
        if defisafety_row.empty and protocol:
            match, score = process.extractOne(protocol, defisafety_names, scorer=fuzz.token_sort_ratio)
            if score >= 85:
                defisafety_row = defisafety[defisafety['norm_name'] == match]
        audited_by_defisafety = not defisafety_row.empty
        audit_score_defisafety = defisafety_row['score'].iloc[0] if audited_by_defisafety and 'score' in defisafety_row.columns else None

        # Github audits (just presence/absence)
        github_row = github[github['norm_name'] == protocol]
        if github_row.empty and protocol:
            match, score = process.extractOne(protocol, github_names, scorer=fuzz.token_sort_ratio)
            if score >= 85:
                github_row = github[github['norm_name'] == match]
        audited_by_github = not github_row.empty

        # --- Chain/category enrichment ---
        # Try to match by address first
        contract_rows = pd.DataFrame()
        if addresses_norm:
            contract_rows = contracts[contracts['address_norm'].isin(addresses_norm)]
        if contract_rows.empty and protocol:
            # Fuzzy match protocol/project name
            match, score = process.extractOne(protocol, contracts_names, scorer=fuzz.token_sort_ratio)
            if score >= 85:
                contract_rows = contracts[contracts['norm_name'] == match]

        chain = list(contract_rows['chain'].unique()) if not contract_rows.empty and 'chain' in contract_rows.columns else []
        category = list(contract_rows['category'].unique()) if not contract_rows.empty and 'category' in contract_rows.columns else []
        contract_count = int(contract_rows.shape[0]) if not contract_rows.empty else 0

        # Compose enrichment
        incident_enriched = dict(incident)
        incident_enriched.update({
            "audited_by_certik": bool(audited_by_certik),
            "audit_score_certik": audit_score_certik,
            "audited_by_defisafety": bool(audited_by_defisafety),
            "audit_score_defisafety": audit_score_defisafety,
            "audited_by_github": bool(audited_by_github),
            "chain": chain,
            "category": category,
            "contract_count": contract_count,
        })
        enriched.append(incident_enriched)

        # Log unmatched
        if not audited_by_certik and not audited_by_defisafety and not audited_by_github and contract_count == 0:
            logging.warning(f"Unmatched: {incident.get('protocol') or incident.get('project') or incident.get('name')}")
            unmatched.append(incident.get('protocol') or incident.get('project') or incident.get('name'))

    print(f"Total incidents enriched: {len(enriched)}")
    print(f"Incidents with no audit or chain/category match: {len(unmatched)}")

    print("Saving enriched dataset to JSON...")
    save_json(enriched, ENRICHED_JSON_PATH)
    print(f"Saved JSON: {ENRICHED_JSON_PATH}")

    print("Saving enriched dataset to CSV...")
    pd.DataFrame(enriched).to_csv(ENRICHED_CSV_PATH, index=False)
    print(f"Saved CSV: {ENRICHED_CSV_PATH}")

if __name__ == "__main__":
    main()